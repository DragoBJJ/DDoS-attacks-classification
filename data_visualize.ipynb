{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2d01a29-8970-4d7a-b04a-48487ef868e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from sklearn.metrics import (\n",
    "     accuracy_score, auc,\n",
    "     classification_report,\n",
    "     confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3f82fe-41e8-49e0-a4da-6766c2941885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_importances_feature(shape, mapped_df, model):\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    ## sorted by importance\n",
    "    indexes = sorted(range(len(importances)), key=lambda i: importances[i], reverse=False)\n",
    "    feature_column_names = [f\"Features name - {mapped_df.columns[i]} - index -  {i}\" for i in indexes]\n",
    "\n",
    "    plt.figure(figsize=(8, 14))\n",
    "    plt.barh(range(shape), importances[indexes], align=\"center\")\n",
    "    plt.yticks(range(shape), feature_column_names)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def check_missing_values(data_frame):\n",
    "    missing_values = data_frame.isnull().sum()\n",
    "    missing_columns = missing_values[missing_values > 0]\n",
    "\n",
    "    total_rows = data_frame.shape[0]\n",
    "\n",
    "    if not missing_columns.empty:\n",
    "        print(\"=== Kolumny z brakującymi wartościami ===\")\n",
    "        for column, count in missing_columns.items():\n",
    "            percentage = (count / total_rows) * 100\n",
    "            print(f\"Kolumna: {column} - {count} brakujących wartości - ({percentage:.2f}% danych)\")\n",
    "    else:\n",
    "        print(\"Brak brakujących wartości w zbiorze danych.\")\n",
    "\n",
    "\n",
    "def visualize_labels(data_frame):\n",
    "    label_counts = data_frame['Label'].value_counts()\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    ax = sns.barplot(x=label_counts.index, y=label_counts.values, palette=\"viridis\", hue=label_counts.index, legend=False)\n",
    "\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "    plt.title('Distribution of samples', fontsize=16)\n",
    "    plt.xlabel('Attack type', fontsize=14)\n",
    "    plt.ylabel('Number of Cases', fontsize=14)\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def time_execution(func, *args, **kwargs):\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    execution_time = (end_time - start_time) / 60\n",
    "    print(f\"time execution: {execution_time:.4f} minut\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def extract_important_features(model, mapped_df, threshold=0.010):\n",
    "    # Importances feature from the model\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    # Get the indices of features that meet the threshold\n",
    "    indices = np.where(importances >= threshold)[0]  # Get indices of features with importance >= threshold\n",
    "\n",
    "    # If no features meet the threshold, return a message\n",
    "    if len(indices) == 0:\n",
    "        print(\"No features with significance >= {}.\".format(threshold))\n",
    "        return\n",
    "\n",
    "    # Get feature names and importances of the selected features\n",
    "    important_feature_names = [mapped_df.columns[i] for i in indices]\n",
    "    important_importances = importances[indices]\n",
    "\n",
    "    # Sort features by importance in descending order\n",
    "    sorted_indices = np.argsort(important_importances)\n",
    "    sorted_feature_names = [important_feature_names[i] for i in sorted_indices]\n",
    "    sorted_importances = important_importances[sorted_indices]\n",
    "\n",
    "    # Create a horizontal bar plot for the important features\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(sorted_feature_names, sorted_importances, align='center')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Features with significance >= {} in the DDoS model.'.format(threshold))\n",
    "    plt.show()\n",
    "\n",
    "    return indices\n",
    "\n",
    " ## Generate and display a detailed confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, title='Confusion Matrix'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                 xticklabels=classes, yticklabels=classes)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualizationMetrics(accuracy, f1, precision, recall):\n",
    "    metrics_data = {\n",
    "     'Metric': ['Accuracy', 'F1 Score', 'Precision', 'Recall'],\n",
    "     'Value': [accuracy, f1, precision, recall]\n",
    "    }\n",
    "\n",
    "    df_metrics = pd.DataFrame(metrics_data)\n",
    "\n",
    "    print(df_metrics)\n",
    "\n",
    "def visualize_model_accuracies(accuracies, title='Model Accuracies Comparison', color='skyblue'):\n",
    "    models = list(accuracies.keys())\n",
    "    values = list(accuracies.values())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.barh(models, values, color=color)\n",
    "    \n",
    "    for bar in bars:\n",
    "        plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2,\n",
    "                 f'{bar.get_width():.4f}', va='center')\n",
    "\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.grid(axis='x')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_model_metrics(metrics, title='Model Performance Metrics Comparison', color='lightcoral'):\n",
    "    # Przygotowanie danych\n",
    "    models = list(metrics.keys())\n",
    "    f1_scores = [metrics[model]['F1 Score'] for model in models]\n",
    "    precisions = [metrics[model]['Precision'] for model in models]\n",
    "    recalls = [metrics[model]['Recall'] for model in models]\n",
    "\n",
    "    # Ustawienia dla wykresu\n",
    "    x = np.arange(len(models))  # lokalizacje na osi x\n",
    "    width = 0.2  # zmniejszona szerokość słupków\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Tworzenie słupków dla każdej metryki\n",
    "    bars1 = ax.bar(x - width, f1_scores, width, label='F1 Score', color=color)\n",
    "    bars2 = ax.bar(x, precisions, width, label='Precision', color='skyblue')\n",
    "    bars3 = ax.bar(x + width, recalls, width, label='Recall', color='lightgreen')\n",
    "\n",
    "    # Dodanie etykiet i tytułu\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models)\n",
    "    ax.legend()\n",
    "\n",
    "    # Dodanie wartości na słupkach\n",
    "    for bars in [bars1, bars2, bars3]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.2f}',\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # przesunięcie w górę\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    # Wyświetlenie wykresu\n",
    "    plt.ylim(0, 1)  # Ustalamy zakres y od 0 do 1\n",
    "    plt.grid(axis='y')\n",
    "    \n",
    "    # Dodanie przestrzeni po prawej stronie wykresu\n",
    "    plt.subplots_adjust(right=0.85)  \n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(model, X_test, Y_test, model_name):\n",
    "    # Binarizacja etykiet\n",
    "    n_classes = len(np.unique(Y_test))\n",
    "    Y_test_bin = label_binarize(Y_test, classes=np.unique(Y_test))\n",
    "\n",
    "    proba = model.predict_proba(X_test)\n",
    "\n",
    "    # Obliczanie krzywych ROC i AUC dla każdej klasy\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(Y_test_bin[:, i], proba[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Rysowanie krzywych ROC\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='black', label='Random Classifier (AUC - 0.50)')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic (ROC) Curve for {model_name}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_model_probabilities(model_probabilities, title='Model Probability Metrics Comparison', color='lightblue'):\n",
    "    # Przygotowanie danych\n",
    "    models = list(model_probabilities.keys())\n",
    "    probabilities = np.array(list(model_probabilities.values()))\n",
    "\n",
    "    # Ustawienia dla wykresu\n",
    "    x = np.arange(len(models))  # lokalizacje na osi x\n",
    "    width = 0.35  # szerokość słupków\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Tworzenie słupków dla każdej klasy\n",
    "    for i in range(probabilities.shape[1]):\n",
    "        ax.bar(x + i * width, probabilities[:, i], width, label=f'Class {i}', color=color)\n",
    "\n",
    "    # Dodanie etykiet i tytułu\n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x + width / 2)\n",
    "    ax.set_xticklabels(models)\n",
    "    ax.legend()\n",
    "\n",
    "    # Dodanie wartości na słupkach\n",
    "    for i in range(probabilities.shape[1]):\n",
    "        for j in range(len(models)):\n",
    "            ax.annotate(f'{probabilities[j, i]:.2f}',\n",
    "                        xy=(j + i * width, probabilities[j, i]),\n",
    "                        xytext=(0, 3),  # przesunięcie w górę\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "\n",
    "    # Wyświetlenie wykresu\n",
    "    plt.ylim(0, 1)  # Ustalamy zakres y od 0 do 1\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
